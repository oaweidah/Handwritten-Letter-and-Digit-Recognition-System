{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4691,
     "status": "ok",
     "timestamp": 1636942207272,
     "user": {
      "displayName": "Sineth Bandara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKdq8bhCUpgQ-7MzvdaGUCoDrG8IEInhYwzCJC=s64",
      "userId": "02739801178643177334"
     },
     "user_tz": -330
    },
    "id": "AzE3LRw5S4Pt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import visualkeras as vk\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16308,
     "status": "ok",
     "timestamp": 1636942223576,
     "user": {
      "displayName": "Sineth Bandara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKdq8bhCUpgQ-7MzvdaGUCoDrG8IEInhYwzCJC=s64",
      "userId": "02739801178643177334"
     },
     "user_tz": -330
    },
    "id": "0uzUNs1LTWe-"
   },
   "outputs": [],
   "source": [
    "# Load all the data from the preprocessing\n",
    "training_data = np.load(\"../numpy/training_data.npy\")\n",
    "testing_data = np.load(\"../numpy/testing_data.npy\")\n",
    "training_tags = np.load(\"../numpy/training_tags.npy\")\n",
    "testing_tags = np.load(\"../numpy/testing_tags.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1636942223580,
     "user": {
      "displayName": "Sineth Bandara",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKdq8bhCUpgQ-7MzvdaGUCoDrG8IEInhYwzCJC=s64",
      "userId": "02739801178643177334"
     },
     "user_tz": -330
    },
    "id": "ZO4XD8H-TjdL",
    "outputId": "b1f400cb-ffc3-45e1-ecce-76f7fb8c9272"
   },
   "outputs": [],
   "source": [
    "# Creating a sequential model (layer stacks)\n",
    "model = Sequential()\n",
    "\n",
    "# Adding a 2D convolutional layer with parameters below\n",
    "# Specifying input shape to what we made it before\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Repeat\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'))\n",
    "\n",
    "# Normalizing the activations of the previous layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Downsampling the input and reducing overfitting\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Adding a dropout layer to randomly set 25% of the previous layer's outputs to 0's to reduce overfitting\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Flattening the output of the previous layer into 1D array (for fully connected layers)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected dense layer with parameters below\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "\n",
    "# Again normalizing the activations of the previous layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Adding a fully connected dense layer (one for each class) + softmax activation function for multi-class classification\n",
    "model.add(Dense(units=36, activation='softmax'))\n",
    "\n",
    "# Compiling  model with parameters below\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mykaSAmzbVmA"
   },
   "outputs": [],
   "source": [
    "# Callback to stop training if validation loss does not improve for 3 epochs (To save time as this part takes ages, can change by changing patience)\n",
    "stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Creating ModelCheckpoint callback to save model weights with lowest training losses\n",
    "loss_checkpoint = ModelCheckpoint(filepath=\"../models/lossModel.h5\",monitor=\"loss\",save_best_only=True,save_weights_only=True,mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mykaSAmzbVmA"
   },
   "outputs": [],
   "source": [
    "# Creating ModelCheckpoint callback to save model weights with lowest validation loss\n",
    "validation_checkpoint = ModelCheckpoint(filepath=\"../models/validationModel.h5\",monitor=\"val_loss\",save_best_only=True,save_weights_only=True,mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mykaSAmzbVmA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1660/1660 [==============================] - 165s 98ms/step - loss: 0.2593 - accuracy: 0.9286 - val_loss: 0.1473 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "1660/1660 [==============================] - 163s 98ms/step - loss: 0.1158 - accuracy: 0.9661 - val_loss: 0.1736 - val_accuracy: 0.9509\n",
      "Epoch 3/10\n",
      "1660/1660 [==============================] - 163s 98ms/step - loss: 0.0900 - accuracy: 0.9732 - val_loss: 0.1753 - val_accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "1660/1660 [==============================] - 167s 101ms/step - loss: 0.0744 - accuracy: 0.9772 - val_loss: 0.5337 - val_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "1660/1660 [==============================] - 162s 98ms/step - loss: 0.0620 - accuracy: 0.9807 - val_loss: 1.0278 - val_accuracy: 0.7905\n",
      "Epoch 6/10\n",
      "1660/1660 [==============================] - 161s 97ms/step - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.2371 - val_accuracy: 0.9379\n",
      "Epoch 7/10\n",
      "1660/1660 [==============================] - 161s 97ms/step - loss: 0.0489 - accuracy: 0.9840 - val_loss: 5.9263 - val_accuracy: 0.3650\n",
      "Epoch 8/10\n",
      "1660/1660 [==============================] - 162s 98ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 6.2362 - val_accuracy: 0.3570\n",
      "Epoch 9/10\n",
      "1660/1660 [==============================] - 163s 98ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 6.9078 - val_accuracy: 0.3655\n",
      "Epoch 10/10\n",
      "1660/1660 [==============================] - 164s 99ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 13.6766 - val_accuracy: 0.2600\n"
     ]
    }
   ],
   "source": [
    "# Training model using specified training and testing data (10 epochs unless improvement doesnt occur in 3 epochs)\n",
    "test = model.fit(training_data,training_tags,validation_data=(testing_data, testing_tags), epochs=10, batch_size=200, callbacks=[stop, loss_checkpoint, validation_checkpoint])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZsHenJlD3G39gEpUDcN/e",
   "collapsed_sections": [],
   "mount_file_id": "1DEOWed-HBHqrgrvunKtx5w4ISOZRtuXo",
   "name": "CNN Architecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
