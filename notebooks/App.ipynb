{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05ecdf0-08db-43e6-9044-a17d051b4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, ReLU, LeakyReLU, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28185a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reset whiteboard to white in between trials  (When you click e)\n",
    "def resetWhiteboard(display): \n",
    "    # Coordinates of whiteboard area\n",
    "    x1, x2, y1, y2 = whiteboardArea['x'][0], whiteboardArea['x'][1], whiteboardArea['y'][0], whiteboardArea['y'][1]\n",
    "    \n",
    "    # Set it to white\n",
    "    display[y1-10:y2+12, x1-10:x2+12] = (255, 255, 255)\n",
    "    \n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe0da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create whiteboard (general GUI of application)\n",
    "def createDisplay():\n",
    "    # Creating title, board, and panel\n",
    "    title = np.zeros((80, 950, 3), dtype=np.uint8)\n",
    "    board = np.zeros((600, 650, 3), dtype=np.uint8)\n",
    "    panel = np.zeros((600, 300, 3), dtype=np.uint8)\n",
    "\n",
    "    # Creating whiteboard area on board\n",
    "    whiteboardArea = (8, 5, 645, 590)\n",
    "    board[whiteboardArea[1]:whiteboardArea[3], whiteboardArea[0]:whiteboardArea[2]] = (255, 255, 255)\n",
    "\n",
    "    # Purple theme for rest of board\n",
    "    cv2.rectangle(board, (whiteboardArea[0], whiteboardArea[1]), (whiteboardArea[2], whiteboardArea[3]), (255, 0, 179), 3)\n",
    "    cv2.rectangle(panel, (1, 4), (290, 590), (255, 0, 179), 2)\n",
    "    cv2.rectangle(panel, (22, 65), (268, 280), (255, 255, 255), 1)\n",
    "    cv2.rectangle(panel, (22, 340), (268, 560), (255, 255, 255), 1)\n",
    "    cv2.line(panel, (145, 340), (145, 560), (255, 255, 255), 1)\n",
    "    cv2.line(panel, (22, 380), (268, 380), (255, 255, 255), 1)\n",
    "\n",
    "    # Adding text\n",
    "    cv2.putText(title, \"    \" + windowName, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "    cv2.putText(panel, \"Action: \", (23, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Top 3 Predictions\", (52, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Prediction\", (42, 362), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Accuracy %\", (168, 362), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, actions[0], (95, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, actionColors[actions[0]], 1)\n",
    "\n",
    "    # Combining diff parts into one display (All images)\n",
    "    display = np.concatenate((board, panel), axis=1)\n",
    "    display = np.concatenate((title, display), axis=0)\n",
    "\n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73bb0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display rest of information on top of previously created background image\n",
    "def createPanel(display):\n",
    "    # Setting status panel to black\n",
    "    for region in statusAreas.values():\n",
    "        pt1, pt2 = region\n",
    "        display[pt1[1]:pt2[1], pt1[0]:pt2[0]] = (0, 0, 0)\n",
    "\n",
    "    # When cropped, display in top right (Preview of crop)\n",
    "    if cropPreview is not None:\n",
    "        pt1, pt2 = statusAreas[\"preview\"]\n",
    "        display[pt1[1]:pt2[1], pt1[0]:pt2[0]] = cv2.resize(cropPreview, (cropPreviewHeight, cropPreviewWidth))\n",
    "\n",
    "    # Display top 3 predictions in the predictions array appropriately\n",
    "    if topPredictions:\n",
    "        currentPredictionCoords = [((725, 505), (830, 505), (0, 255, 0)),((725, 562), (830, 562), (0, 179, 255)),((725, 619), (830, 619), (0, 0, 255))]\n",
    "        for i, (layer, acc) in enumerate(topPredictions.items()):\n",
    "            if i >= len(currentPredictionCoords):\n",
    "                break\n",
    "            layerCoord, accCoord, color = currentPredictionCoords[i]\n",
    "            cv2.putText(display, layer, layerCoord, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.putText(display, str(acc), accCoord, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # If there are less than three predictions, display \"_\" instead\n",
    "        for i in range(len(topPredictions), 3):\n",
    "            layerCoord, accCoord, color = currentPredictionCoords[i]\n",
    "            cv2.putText(display, \"_\", layerCoord, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.putText(display, \"_\", accCoord, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    # Display current action (Draw, Crop, or nothing [N/A])\n",
    "    cv2.putText(display, currentAction, (745, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, actionColors[currentAction], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe750ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main Function to handle events (Drawing, erasing, cropping)\n",
    "def onMouseClick(event, x, y, flags, params):\n",
    "    # Getting x and y limits for whiteboard\n",
    "    x_min, x_max = whiteboardArea[\"x\"]\n",
    "    y_min, y_max = whiteboardArea[\"y\"]\n",
    "    global leftMouseDown, rightMouseDown\n",
    "    global display, boundRectangleCoords, cropPreview, topPredictions\n",
    "    \n",
    "    # If action is draw: proceed to handle it\n",
    "    if currentAction == actions[1]:\n",
    "        # Checking type of mouse event and update button state\n",
    "        if event == cv2.EVENT_RBUTTONUP:\n",
    "            rightMouseDown = False\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "             leftMouseDown = False\n",
    "        # Otherwise if you are within drawing bounds\n",
    "        elif x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "            # and if you are left clicking and moving (draw) or right clicking and moving (erase [Draw in white])\n",
    "            if event in [cv2.EVENT_LBUTTONDOWN, cv2.EVENT_MOUSEMOVE]:\n",
    "                # Set color of circle (combination of circles create line) based on button state (western purple for draw, white for erase)\n",
    "                color = (255, 0, 179) if leftMouseDown else (255, 255, 255) if rightMouseDown else None\n",
    "                if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                    leftMouseDown = True\n",
    "                elif (event == cv2.EVENT_MOUSEMOVE and leftMouseDown):\n",
    "                    pass\n",
    "                elif event == cv2.EVENT_MOUSEMOVE and rightMouseDown:\n",
    "                    pass\n",
    "                else:\n",
    "                    return\n",
    "                \n",
    "                # Draw a circle (filled) on the board and show it (combination of circles create line)\n",
    "                # (color is either white or purple for draw/erase)\n",
    "                # Technically we never erase we just draw over it in white\n",
    "                cv2.circle(display, (x, y), 8, color, -1)\n",
    "                cv2.imshow(windowName, display)\n",
    "            elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "                rightMouseDown = True\n",
    "    \n",
    "    # If action is crop: proceed to handle it\n",
    "    elif currentAction == actions[2]:\n",
    "        # When user clicks left mouse, store coordinates of starting point (Top left corner of rectangle)\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            boundRectangleCoords = (x, y)\n",
    "        # When user releases left mouse, crop image, invert colors, \n",
    "        # Predict character, display selection in top right, show predictions in bottom left\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            topCoord, bottomCoord = boundRectangleCoords, (x, y)\n",
    "            cropPreview = display[topCoord[1]:bottomCoord[1], topCoord[0]:bottomCoord[0]].copy()\n",
    "            cropPreview = cv2.bitwise_not(cropPreview)\n",
    "            topPredictions = predict(model, cropPreview)\n",
    "            displayCopy = display.copy()\n",
    "            cv2.rectangle(displayCopy, topCoord, bottomCoord, (255, 0, 179), 2)\n",
    "            createPanel(displayCopy)\n",
    "            cv2.imshow(windowName, displayCopy)\n",
    "            boundRectangleCoords = None\n",
    "\n",
    "        # Showing rectange that highlights the croppped part (When left mouse is clicked down)\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and boundRectangleCoords is not None:\n",
    "            topCoord, bottomCoord = boundRectangleCoords, (x, y)\n",
    "            displayCopy = display.copy()\n",
    "            cv2.rectangle(displayCopy, topCoord, bottomCoord, (255, 0, 179), 2)\n",
    "            cv2.imshow(windowName, displayCopy)\n",
    "\n",
    "        # When there is nothing selected, display all previous info (ie: change nothing)\n",
    "        elif event == cv2.EVENT_LBUTTONUP and boundRectangleCoords is None:\n",
    "            createPanel(display)\n",
    "            cv2.imshow(windowName, display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977731a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize input data to improve training and model performance.\n",
    "def load_model(path):\n",
    "    # Defining input shape\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    \n",
    "    # Adding a convolutional layer with 32 filters (5x5) / Using ReLU activation\n",
    "    x = Conv2D(32, (5, 5), activation=\"relu\")(inputs)\n",
    "    \n",
    "    # Adding batch normalization to normalize activations of previous layer\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Repeat\n",
    "    x = Conv2D(32, (5, 5), activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Adding a max pooling layer (pool size 2x2) / This should downsample the input along spatial dimensions\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Adding dropout regularization to randomly set 25% of activations to 0 / This should help prevent overfitting\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Batch normalization again\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Flattening output of previous layer\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Adding a fully connected dense layer with 256 units + ReLU activation\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    \n",
    "    # Repeat with 36 units and softmax activation / This is the output layer (predicted probabilites)\n",
    "    outputs = Dense(36, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Defining model with input/output layers\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compiling model with conditions seen below\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Loading weights of model from given path\n",
    "    model.load_weights(path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0716bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main prediction function\n",
    "def predict(model, image):\n",
    "    # Defining list of layers (All capital letters and numbers)\n",
    "    layers = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z','0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    \n",
    "    # Converting image to grayscale, resizing it, and normalizing pixel values of image between 0 and 1\n",
    "    image = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (28, 28)) / 255.0\n",
    "\n",
    "    # Reshape image to match input shape of model\n",
    "    image = np.reshape(image, (1, image.shape[0], image.shape[1], 1))\n",
    "    \n",
    "    # Using model to predict\n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    # Finding top 3 predicted layers + accuracy\n",
    "    topPredictions = {}\n",
    "    indices = np.argsort(prediction)[0][::-1][:3] # Getting indices of top 3 guesses in descending order\n",
    "    for i in indices:\n",
    "        acc = round(prediction[0][i] * 100, 1)\n",
    "        if acc > 0:\n",
    "            layer = layers[i]\n",
    "            topPredictions[layer] = acc\n",
    "\n",
    "    return topPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01eface5-a37a-4a09-a718-96310339855d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 7 layers, found 6 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m statusAreas \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\"\u001b[39m: ((\u001b[38;5;241m736\u001b[39m, \u001b[38;5;241m97\u001b[39m), (\u001b[38;5;241m828\u001b[39m, \u001b[38;5;241m131\u001b[39m)),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreview\u001b[39m\u001b[38;5;124m\"\u001b[39m: ((\u001b[38;5;241m676\u001b[39m, \u001b[38;5;241m150\u001b[39m), (\u001b[38;5;241m914\u001b[39m, \u001b[38;5;241m356\u001b[39m)),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m: ((\u001b[38;5;241m678\u001b[39m, \u001b[38;5;241m468\u001b[39m), (\u001b[38;5;241m790\u001b[39m, \u001b[38;5;241m632\u001b[39m)),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccs\u001b[39m\u001b[38;5;124m\"\u001b[39m: ((\u001b[38;5;241m801\u001b[39m, \u001b[38;5;241m468\u001b[39m), (\u001b[38;5;241m913\u001b[39m, \u001b[38;5;241m632\u001b[39m))}\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Loading prediction model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/validationModel.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Setting up the display (It is an image)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m display \u001b[38;5;241m=\u001b[39m createDisplay()\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Loading weights of model from given path\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\legacy\\hdf5_format.py:808\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    806\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    812\u001b[0m     )\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    816\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 7 layers, found 6 saved layers."
     ]
    }
   ],
   "source": [
    "# Main running code (main function basically)\n",
    "# Mouse buttons start off unclicked\n",
    "leftMouseDown = rightMouseDown = False \n",
    "boundRectangleCoords = lbdCoord = lbuCoord = None \n",
    "\n",
    "# Defining whiteboard area\n",
    "whiteboardArea = {\"x\": (20, 633), \"y\": (98, 657)} \n",
    "windowName = \"D: Draw | C: Crop | R: Reset | E: End\"\n",
    "\n",
    "# Creating dictionary to store results\n",
    "topPredictions = dict() \n",
    "cropPreviewHeight, cropPreviewWidth, cropPreview = 238, 206, None\n",
    "\n",
    "# All available actions\n",
    "actions = [\"NONE\", \"DRAW\", \"CROP\"]\n",
    "\n",
    "# Their respective word colors\n",
    "actionColors = {actions[0]: (0, 0, 255), actions[1]: (0, 255, 0),actions[2]: (0, 255, 255)}\n",
    "\n",
    "# Action is nothing yet\n",
    "currentAction = actions[0]\n",
    "\n",
    "# Putting layers where they belong\n",
    "statusAreas = {\"Action\": ((736, 97), (828, 131)),\"preview\": ((676, 150), (914, 356)),\"layers\": ((678, 468), (790, 632)),\"accs\": ((801, 468), (913, 632))}\n",
    "\n",
    "# Loading prediction model\n",
    "model = load_model(\"../models/validationModel.h5\")\n",
    "\n",
    "# Setting up the display (It is an image)\n",
    "display = createDisplay()\n",
    "cv2.imshow(windowName, display)\n",
    "cv2.setMouseCallback(windowName, onMouseClick)\n",
    "\n",
    "# Loop made to constantly check for input and react appropriately\n",
    "# When key press is detected (1 second intervals) new action name is displayed and action is changed\n",
    "while True:\n",
    "    k = cv2.waitKey(1)\n",
    "    # D for draw\n",
    "    if k == ord('d'):\n",
    "        currentAction = actions[1]\n",
    "        createPanel(display)\n",
    "        cv2.imshow(windowName, display)\n",
    "    # C for crop\n",
    "    elif k == ord('c'):\n",
    "        currentAction = actions[2]\n",
    "        createPanel(display)\n",
    "        cv2.imshow(windowName, display)\n",
    "    # R for reset\n",
    "    elif k == ord('r'):\n",
    "        resetWhiteboard(display)\n",
    "        cv2.imshow(windowName, display)\n",
    "    # E for end\n",
    "    elif k == ord('e'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08872f6-ebc9-40df-8b0b-becb55380946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
